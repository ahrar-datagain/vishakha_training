{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30761,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Tensor Flow with Keras\nKeras is now integrated into TensorFlow as tf.keras, providing a high-level API to build and train models easily. It simplifies many tasks with an intuitive interface while still leveraging TensorFlow's powerful backend\n\n\n#### Keras:\n* Keras is a Python-based, open-source deep learning framework that helps simplify the process of creating neural networks.\n* Keras has a high-level abstraction and simple APIs that make it relatively easy to work with.\n* Keras can run on top of multiple back-ends, including TensorFlow, PyTorch, and JAX. This allows you to choose the backend that will deliver the best performance for your model.\n\n#### Using Tensor flow with Keras:\nwe are creating a simple dataset to predict whether an individual will buy a product based on their age and income.","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19"}},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense\nimport numpy as np","metadata":{"execution":{"iopub.status.busy":"2024-09-02T12:32:44.841469Z","iopub.execute_input":"2024-09-02T12:32:44.841890Z","iopub.status.idle":"2024-09-02T12:33:00.037008Z","shell.execute_reply.started":"2024-09-02T12:32:44.841851Z","shell.execute_reply":"2024-09-02T12:33:00.035708Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"# Preparing data\n# Features: [age, income]\nX = np.array([[25, 50000], [45, 80000], [35, 60000], [50, 90000], [30, 55000], [40, 70000]])\n# Labels: 1 if they bought the product, 0 if they did not\ny = np.array([0, 1, 0, 1, 0, 1])\n\n# Split the data into training and testing sets\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Standardize the features (important for neural networks)\nfrom sklearn.preprocessing import StandardScaler\nscaler = StandardScaler()\nX_train = scaler.fit_transform(X_train)\nX_test = scaler.transform(X_test)","metadata":{"execution":{"iopub.status.busy":"2024-09-02T12:33:00.038918Z","iopub.execute_input":"2024-09-02T12:33:00.039526Z","iopub.status.idle":"2024-09-02T12:33:00.606559Z","shell.execute_reply.started":"2024-09-02T12:33:00.039487Z","shell.execute_reply":"2024-09-02T12:33:00.605409Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"**Building the model:**","metadata":{}},{"cell_type":"code","source":"# Create a simple neural network model\nmodel = Sequential([\n    Dense(8, input_shape=(X_train.shape[1],), activation='relu'),  # Input layer with 8 neurons\n    Dense(4, activation='relu'),  # Hidden layer with 4 neurons\n    Dense(1, activation='sigmoid')  # Output layer with 1 neuron (binary classification)\n])\n","metadata":{"execution":{"iopub.status.busy":"2024-09-02T12:37:39.577255Z","iopub.execute_input":"2024-09-02T12:37:39.577713Z","iopub.status.idle":"2024-09-02T12:37:39.610502Z","shell.execute_reply.started":"2024-09-02T12:37:39.577673Z","shell.execute_reply":"2024-09-02T12:37:39.609352Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":"**Compile the model :**","metadata":{}},{"cell_type":"code","source":"# Compile the model with an optimizer, loss function, and metric\nmodel.compile(optimizer='adam',\n              loss='binary_crossentropy',\n              metrics=['accuracy'])\n","metadata":{"execution":{"iopub.status.busy":"2024-09-02T12:52:30.291839Z","iopub.execute_input":"2024-09-02T12:52:30.292253Z","iopub.status.idle":"2024-09-02T12:52:30.304865Z","shell.execute_reply.started":"2024-09-02T12:52:30.292217Z","shell.execute_reply":"2024-09-02T12:52:30.303403Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"# Train Model:\n# Fit the model to the training data\nhistory = model.fit(X_train, y_train, epochs=20, batch_size=1, validation_split=0.2)\n","metadata":{"execution":{"iopub.status.busy":"2024-09-02T12:52:32.548038Z","iopub.execute_input":"2024-09-02T12:52:32.548446Z","iopub.status.idle":"2024-09-02T12:52:35.160345Z","shell.execute_reply.started":"2024-09-02T12:52:32.548410Z","shell.execute_reply":"2024-09-02T12:52:35.159152Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"Epoch 1/20\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 99ms/step - accuracy: 1.0000 - loss: 0.6801 - val_accuracy: 1.0000 - val_loss: 0.5401\nEpoch 2/20\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 1.0000 - loss: 0.6717 - val_accuracy: 1.0000 - val_loss: 0.5354\nEpoch 3/20\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 1.0000 - loss: 0.6786 - val_accuracy: 1.0000 - val_loss: 0.5323\nEpoch 4/20\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 1.0000 - loss: 0.6698 - val_accuracy: 1.0000 - val_loss: 0.5279\nEpoch 5/20\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 1.0000 - loss: 0.6688 - val_accuracy: 1.0000 - val_loss: 0.5236\nEpoch 6/20\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 1.0000 - loss: 0.6737 - val_accuracy: 1.0000 - val_loss: 0.5199\nEpoch 7/20\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 1.0000 - loss: 0.6761 - val_accuracy: 1.0000 - val_loss: 0.5164\nEpoch 8/20\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 1.0000 - loss: 0.6754 - val_accuracy: 1.0000 - val_loss: 0.5127\nEpoch 9/20\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 1.0000 - loss: 0.6715 - val_accuracy: 1.0000 - val_loss: 0.5083\nEpoch 10/20\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 1.0000 - loss: 0.6642 - val_accuracy: 1.0000 - val_loss: 0.5036\nEpoch 11/20\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 1.0000 - loss: 0.6735 - val_accuracy: 1.0000 - val_loss: 0.4998\nEpoch 12/20\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 1.0000 - loss: 0.6622 - val_accuracy: 1.0000 - val_loss: 0.4950\nEpoch 13/20\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 0.6722 - val_accuracy: 1.0000 - val_loss: 0.4912\nEpoch 14/20\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 1.0000 - loss: 0.6714 - val_accuracy: 1.0000 - val_loss: 0.4871\nEpoch 15/20\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 1.0000 - loss: 0.6669 - val_accuracy: 1.0000 - val_loss: 0.4824\nEpoch 16/20\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 1.0000 - loss: 0.6661 - val_accuracy: 1.0000 - val_loss: 0.4777\nEpoch 17/20\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 1.0000 - loss: 0.6694 - val_accuracy: 1.0000 - val_loss: 0.4733\nEpoch 18/20\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 1.0000 - loss: 0.6561 - val_accuracy: 1.0000 - val_loss: 0.4679\nEpoch 19/20\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 1.0000 - loss: 0.6681 - val_accuracy: 1.0000 - val_loss: 0.4635\nEpoch 20/20\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 1.0000 - loss: 0.6539 - val_accuracy: 1.0000 - val_loss: 0.4579\n","output_type":"stream"}]},{"cell_type":"markdown","source":"**Evaluate the model**","metadata":{}},{"cell_type":"code","source":"# Evaluate the model on the test data\nloss, accuracy = model.evaluate(X_test, y_test)\nprint(f'Test loss: {loss:.4f}')\nprint(f'Test accuracy: {accuracy:.4f}')\n","metadata":{"execution":{"iopub.status.busy":"2024-09-02T12:52:43.840879Z","iopub.execute_input":"2024-09-02T12:52:43.841304Z","iopub.status.idle":"2024-09-02T12:52:44.057071Z","shell.execute_reply.started":"2024-09-02T12:52:43.841259Z","shell.execute_reply":"2024-09-02T12:52:44.055772Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 150ms/step - accuracy: 1.0000 - loss: 0.6013\nTest loss: 0.6013\nTest accuracy: 1.0000\n","output_type":"stream"}]},{"cell_type":"markdown","source":"**Make Predictions**","metadata":{}},{"cell_type":"code","source":"# Predict whether new individuals will buy the product\nnew_data = np.array([[28, 52000], [48, 85000]])\nnew_data = scaler.transform(new_data)  # Standardize the new data\npredictions = model.predict(new_data)\n\n# Convert predictions to binary outcomes\npredicted_classes = (predictions > 0.5).astype(int)\nprint(\"Predicted classes:\", predicted_classes)\n","metadata":{"execution":{"iopub.status.busy":"2024-09-02T12:52:47.909871Z","iopub.execute_input":"2024-09-02T12:52:47.910260Z","iopub.status.idle":"2024-09-02T12:52:48.036644Z","shell.execute_reply.started":"2024-09-02T12:52:47.910226Z","shell.execute_reply":"2024-09-02T12:52:48.035562Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stdout","text":"\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step\nPredicted classes: [[0]\n [1]]\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# **Building the model:**\n\nThere are three types of a models:\n\n**1. Sequential Model**:\n\n*   The most straightforward model in Keras.\n    \n*   Layers are added in sequence, one after the other.\n    \n*   Best for simple feedforward neural networks where each layer has exactly one input tensor and one output tensor.\n    \n```python\n\nmodel = Sequential(\\[\n\n            Dense(64, activation='relu', input\\_shape=(input\\_dim,)),\n\n            Dense(32, activation='relu'),\n\n            Dense(1, activation='sigmoid')\n\n            \\])\n```\n\n**2. Functional API**:\n\n*   More flexible than Sequential.\n    \n*   Allows for models with multiple inputs, outputs, or shared layers.\n    \n*   Useful for more complex models like multi-input/output models or models with non-linear topology.\n    \n```python\nfrom tensorflow.keras.layers import Input, Dense\n\nfrom tensorflow.keras.models import Model\n\ninputs = Input(shape=(input\\_dim,))\n\nx = Dense(64, activation='relu')(inputs)\n\nx = Dense(32, activation='relu')(x)\n\noutputs = Dense(1, activation='sigmoid')(x)\n\nmodel = Model(inputs=inputs, outputs=outputs)\n```\n\n\n**3. Model Subclassing**:\n\n*   The most flexible approach.\n    \n*   Allows you to define your own forward pass using Python code.\n    \n*   Best for custom layers or models that cannot be represented as a sequence or functional API model.\n    \n```python\nclass MyModel(tf.keras.Model):\n\ndef \\_\\_init\\_\\_(self):\n\n    super(MyModel, self).\\_\\_init\\_\\_()\n\n        self.dense1 = Dense(64, activation='relu')\n\n        self.dense2 = Dense(32, activation='relu')\n\n        self.dense3 = Dense(1, activation='sigmoid')\n\n    def call(self, inputs):\n\n        x = self.dense1(inputs)\n\n        x = self.dense2(x)\n\n        return self.dense3(x)\n\nmodel = MyModel()\n```\n\n### Types of Layers\n\n1.  **Dense Layer**:\n    \n    *   Fully connected layer where each neuron is connected to every neuron in the previous layer.\n        \n    *   Common in feedforward networks.\n        \n    **Parameters:**\n    *   units: Number of neurons in the layer.\n        \n    *   activation: Activation function (e.g., 'relu', 'sigmoid', 'tanh').\n    \n    ```python\n        Dense(64, activation='relu')\n    ```\n        \n2.  **Convolutional Layers**:\n    \n    *   Used primarily in image processing tasks.\n        \n    *   Applies a convolution operation to the input to extract features.\n        \n    **Parameters:**\n    *   filters: Number of output filters (i.e., the number of feature maps).\n        \n    *   kernel\\_size: Size of the convolution window (e.g., (3, 3) for 2D).\n        \n    *   strides: Step size of the convolution.\n        \n    *   padding: 'same' or 'valid' (whether to pad the input).\n    \n    ```python\n        Conv2D(32, kernel_size=(3, 3), activation='relu')\n     ```\n        \n3.  **Pooling Layers**:\n    \n    *   Reduces the spatial dimensions of the input.\n        \n    *   Helps to downsample the input and reduce computation.\n        \n    **Parameters:**\n    *   pool\\_size: Size of the pooling window (e.g., (2, 2)).\n        \n    *   strides: Step size of pooling.\n    \n    ```python\n    MaxPooling2D(pool_size=(2, 2))\n    ```\n        \n4.  **Recurrent Layers (LSTM, GRU, SimpleRNN)**:\n    \n    *   Used for sequential data like time series or text.\n        \n    *   Maintains a state to capture temporal dependencies.\n        \n    **Parameters:**\n    *   units: Number of units (neurons) in the layer.\n        \n    *   return\\_sequences: Whether to return the full sequence or just the output at the last time step.\n    ```python\n    LSTM(50, return_sequences=True)\n    ```\n    \n        \n5.  **Dropout Layer:**:\n    \n    *   Regularization technique to prevent overfitting.\n        \n    *   Randomly sets a fraction of input units to 0 at each update during training.\n        \n    **Parameters:**\n    *   rate: Fraction of the input units to drop (e.g., 0.5 means 50% of inputs are dropped).\n    ```python\n    Dropout(0.5)\n    ```\n        \n\n### Key Model Parameters\n\nInput Shape, Activation Functions (relu, sigmoid, softmax),  Loss function, optimizer.\n        \n\n### What Can Be Built\n\n1.  **Classification Models**:\n    \n    *   Predict categories or classes (e.g., spam detection, image classification).\n        \n    *   Use softmax or sigmoid in the output layer.\n        \n2.  **Regression Models**:\n    \n    *   Predict continuous values (e.g., house prices, stock prices).\n        \n    *   Use linear activation (or no activation) in the output layer.\n        \n3.  **Image Processing Models**:\n    \n    *   Utilize convolutional layers (e.g., object detection, facial recognition).\n        \n    *   Combine Conv2D, MaxPooling, and Dense layers.\n        \n4.  **Time Series/Sequence Models**:\n    \n    *   Use recurrent layers like LSTM or GRU (e.g., predicting stock prices over time, language translation).\n        \n    *   Can also involve 1D Convolutional layers.\n        \n5.  **Generative Models**:\n    \n    *   Create new data (e.g., GANs for image generation, autoencoders for anomaly detection).\n        \n    *   Use a combination of dense and convolutional layers with unique architectures.\n        \n6.  **Multi-Input/Output Models**:\n    \n    *   Models with multiple inputs or outputs (e.g., predicting both product purchase likelihood and customer satisfaction).\n        \n    *   Built using the Functional API.","metadata":{}}]}