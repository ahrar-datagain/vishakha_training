{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":2391843,"sourceType":"datasetVersion","datasetId":1446091}],"dockerImageVersionId":30761,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"Scikit-learn is an open-source machine learning library that provides simple and efficient tools for data analysis and modeling. It is built on [NumPy](https://www.geeksforgeeks.org/introduction-to-numpy/), [SciPy](https://www.geeksforgeeks.org/scipy-integration/), and [Matplotlib,](https://www.geeksforgeeks.org/python-introduction-matplotlib/) making it a powerful tool for tasks like classification, regression, clustering, and dimensionality reduction.\n\n*   [**Classification**](https://www.geeksforgeeks.org/getting-started-with-classification/)**:** Classification involves teaching a computer to categorize things. For example, a model could be built to determine whether an email is spam or not.\n    \n*   [**Regression**](https://www.geeksforgeeks.org/ml-classification-vs-regression/)**:** Regression predicting numbers based on other numbers. For instance, a model could predict house prices using factors like location, size, and age.\n    \n*   [**Clustering**](https://www.geeksforgeeks.org/clustering-in-machine-learning/)**:** Clustering involves finding patterns in data and grouping similar items together. For example, customers could be segmented into different groups based on their shopping habits.\n    \n*   [**Dimensionality Reduction**](https://www.geeksforgeeks.org/dimensionality-reduction/)**:** Dimensionality reduction helps focus on essential data parts while discarding noise. This is useful when dealing with a lot of data that isn’t all relevant.\n\nFeatures of Scikit-Learn\n------------------------\n\nScikit-learn is indeed a versatile tool for machine learning tasks, offering a wide range of features to address various aspects of the data science pipeline. let’s examine prime key features of scikit-learn:\n\n### **Supervised Learning**\n\n*   **Classification:** Algorithms for predicting categorical labels, including [logistic regression](https://www.geeksforgeeks.org/understanding-logistic-regression/), [decision trees](https://www.geeksforgeeks.org/decision-tree-introduction-example/), [random forests](https://www.geeksforgeeks.org/random-forest-algorithm-in-machine-learning/), [support vector machines (SVMs)](https://www.geeksforgeeks.org/support-vector-machine-algorithm/) and [gradient boosting](https://www.geeksforgeeks.org/ml-gradient-boosting/).\n    \n*   **Regression:** Algorithms for predicting continuous outputs, including [linear regression](https://www.geeksforgeeks.org/ml-linear-regression/), support vector regression, and [decision tree regression.](https://www.geeksforgeeks.org/python-decision-tree-regression-using-sklearn/)\n    \n\n### **Unsupervised Learning**\n\n*   **Clustering:** Techniques for grouping data points into similar clusters, including [K-means clustering](https://www.geeksforgeeks.org/k-means-clustering-introduction/), [DBSCAN,](https://www.geeksforgeeks.org/dbscan-clustering-in-ml-density-based-clustering/) and [hierarchical clustering.](https://www.geeksforgeeks.org/hierarchical-clustering/)\n    \n*   **Dimensionality Reduction:** Methods for reducing the number of features in your data, such as [principal component analysis (PCA).](https://www.geeksforgeeks.org/principal-component-analysis-pca/)\n    \n\n### **Data Preprocessing**\n\n*   [**Data Splitting**](https://www.geeksforgeeks.org/splitting-data-for-machine-learning-models/)**:** Functions to split your data into training and testing sets for model evaluation.\n    \n*   [**Feature Scaling**](https://www.geeksforgeeks.org/ml-feature-scaling-part-2/)**:** Techniques for normalizing the scale of your features.\n    \n*   [**Feature Selection**](https://www.geeksforgeeks.org/feature-selection-techniques-in-machine-learning/)**:** Methods to identify and select the most relevant features for your model.\n    \n*   [**Feature Extraction**](https://www.geeksforgeeks.org/difference-between-feature-selection-and-feature-extraction/)**:** Tools to create new features from existing ones, such as text vectorization for natural language processing tasks.\n    \n\n### **Model Evaluation**\n\n*   **Metrics:** Functions to calculate performance metrics like accuracy, [precision, recall](https://www.geeksforgeeks.org/metrics-for-machine-learning-model/), and [F1-score](https://www.geeksforgeeks.org/f1-score-in-machine-learning/) for classification models, and mean squared error (MSE) for regression models.\n    \n*   **Model Selection:** Tools for selecting the best model hyperparameters through techniques like [grid search](https://www.geeksforgeeks.org/comparing-randomized-search-and-grid-search-for-hyperparameter-estimation-in-scikit-learn/) and randomized search.\n    \n\n### **Additional Features**\n\n*   **Inbuilt datasets:** Scikit-learn provides a variety of sample datasets for experimentation and learning purposes.\n    \n*   **Easy to Use API:** Scikit-learn is known for its consistent and user-friendly API, making it accessible to both beginners and experienced data scientists.\n    \n*   **Open Source:** Scikit-learn is an open-source library with a large and active community, ensuring continuous development and support.","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19"}},{"cell_type":"markdown","source":"### Classification – **Logistic Regression Algorithm Example**\n\nLogistic Regression is a binary classification algorithm that estimates probabilities of a binary outcome. It’s used for problems like spam detection, medical diagnosis, and credit scoring. It’s chosen for its simplicity, interpretability, and effectiveness in linearly separable datasets.","metadata":{}},{"cell_type":"code","source":"# Importing necessary libraries\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn import datasets\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score, classification_report\n\n# Load Iris dataset\niris = datasets.load_iris()\nX = iris.data\ny = iris.target\n\n# Splitting the dataset into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n\n# Standardizing features\nscaler = StandardScaler()\nX_train = scaler.fit_transform(X_train)\nX_test = scaler.transform(X_test)\n\n# Training the logistic regression model\nlog_reg = LogisticRegression()\nlog_reg.fit(X_train, y_train)\n\n# Making predictions on the testing set\ny_pred = log_reg.predict(X_test)\n\n# Evaluating the model\naccuracy = accuracy_score(y_test, y_pred)\nprint(\"Accuracy:\", accuracy)\n","metadata":{"execution":{"iopub.status.busy":"2024-08-27T08:36:33.498413Z","iopub.execute_input":"2024-08-27T08:36:33.499693Z","iopub.status.idle":"2024-08-27T08:36:33.529918Z","shell.execute_reply.started":"2024-08-27T08:36:33.499634Z","shell.execute_reply":"2024-08-27T08:36:33.527665Z"},"jupyter":{"source_hidden":true,"outputs_hidden":true},"collapsed":true,"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"Accuracy: 1.0\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### Classification – KNN Classifier **Algorithm Example**\n\nK-Nearest Neighbors (KNN) algorithm classifies data points based on the majority class of their nearest neighbors. It’s useful for simple classification tasks, particularly when data is not linearly separable or when decision boundaries are complex. It’s used in recommendation systems, handwriting recognition, and medical diagnosis.","metadata":{}},{"cell_type":"code","source":"from sklearn.datasets import load_iris\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.neighbors import KNeighborsClassifier\n\n# Load the Iris dataset\niris = load_iris()\nX_train, X_test, y_train, y_test = train_test_split(iris.data, iris.target, test_size=0.2, random_state=42)\n\n# Initialize the KNN classifier\nknn = KNeighborsClassifier(n_neighbors=3)\n\n# Train the classifier\nknn.fit(X_train, y_train)\n\n# Make predictions on the test data\npredictions = knn.predict(X_test)\n\n# Evaluate the model\naccuracy = knn.score(X_test, y_test)\nprint(\"Accuracy:\", accuracy)\n","metadata":{"execution":{"iopub.status.busy":"2024-08-27T08:36:33.532583Z","iopub.execute_input":"2024-08-27T08:36:33.533004Z","iopub.status.idle":"2024-08-27T08:36:33.561875Z","shell.execute_reply.started":"2024-08-27T08:36:33.532962Z","shell.execute_reply":"2024-08-27T08:36:33.559819Z"},"jupyter":{"source_hidden":true,"outputs_hidden":true},"collapsed":true,"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"Accuracy: 1.0\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### Regression – Linear Regression Algorithm Example\n\nLinear Regression fits a linear model to observed data points, predicting continuous outcomes based on input features. It’s used when exploring relationships between variables and making predictions. Applications include economics, finance, engineering, and social sciences.\n\njust see the code below for understanding purpose, housing is not fetched properly here.","metadata":{}},{"cell_type":"code","source":"from sklearn.datasets import fetch_california_housing\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error\n\n# Load the California Housing dataset\nhousing = fetch_california_housing()\nX_train, X_test, y_train, y_test = train_test_split(housing.data, housing.target, test_size=0.2, random_state=42)\n\n# Initialize the Linear Regression model\nlr = LinearRegression()\n\n# Train the model\nlr.fit(X_train, y_train)\n\n# Make predictions on the test data\npredictions = lr.predict(X_test)\n\n# Evaluate the model\nmse = mean_squared_error(y_test, predictions)\nprint(\"Mean Squared Error:\", mse)","metadata":{"execution":{"iopub.status.busy":"2024-08-27T08:43:23.698680Z","iopub.execute_input":"2024-08-27T08:43:23.699271Z","iopub.status.idle":"2024-08-27T08:43:23.707184Z","shell.execute_reply.started":"2024-08-27T08:43:23.699202Z","shell.execute_reply":"2024-08-27T08:43:23.705492Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":"### Clustering – KMeans Algorithm Example\n\nKMeans algorithm partitions data into k clusters based on similarity. It’s used for unsupervised clustering tasks like customer segmentation, image compression, and anomaly detection. Ideal when data’s structure is unknown but grouping is desired.","metadata":{}},{"cell_type":"code","source":"from sklearn.datasets import load_iris\nfrom sklearn.cluster import KMeans\n\n# Load the Iris dataset\niris = load_iris()\n\n# Initialize the KMeans clustering model\nkmeans = KMeans(n_clusters=3)\n\n# Fit the model to the data\nkmeans.fit(iris.data)\n\n# Get the cluster labels\ncluster_labels = kmeans.labels_\n\nprint(\"Cluster Labels:\", cluster_labels)\n","metadata":{"execution":{"iopub.status.busy":"2024-08-27T08:44:45.616338Z","iopub.execute_input":"2024-08-27T08:44:45.617041Z","iopub.status.idle":"2024-08-27T08:44:45.876234Z","shell.execute_reply.started":"2024-08-27T08:44:45.616963Z","shell.execute_reply":"2024-08-27T08:44:45.874442Z"},"jupyter":{"source_hidden":true,"outputs_hidden":true},"collapsed":true,"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"Cluster Labels: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 2 2 2 2 0 2 2 2 2\n 2 2 0 0 2 2 2 2 0 2 0 2 0 2 2 0 0 2 2 2 2 2 0 2 2 2 2 0 2 2 2 0 2 2 2 0 2\n 2 0]\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n  warnings.warn(\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### Dimensionality Reduction – PCA Example\n\nPCA (Principal Component Analysis) reduces the dimensionality of data by finding the most important features. It’s used for visualizing high-dimensional data, noise reduction, and speeding up machine learning algorithms. Commonly applied in image processing, genetics, and finance.","metadata":{"execution":{"iopub.status.busy":"2024-08-27T08:47:11.028864Z","iopub.execute_input":"2024-08-27T08:47:11.029468Z","iopub.status.idle":"2024-08-27T08:47:11.041398Z","shell.execute_reply.started":"2024-08-27T08:47:11.029415Z","shell.execute_reply":"2024-08-27T08:47:11.038942Z"}}},{"cell_type":"code","source":"from sklearn.datasets import load_digits\nfrom sklearn.decomposition import PCA\n\n# Load the digits dataset\ndigits = load_digits()\n\n# Initialize PCA for dimensionality reduction\npca = PCA(n_components=2)\n\n# Apply PCA to the data\nreduced_data = pca.fit_transform(digits.data)\n\nprint(\"Original data shape:\", digits.data.shape)\nprint(\"Reduced data shape:\", reduced_data.shape)\n","metadata":{"execution":{"iopub.status.busy":"2024-08-27T08:47:27.946324Z","iopub.execute_input":"2024-08-27T08:47:27.946830Z","iopub.status.idle":"2024-08-27T08:47:28.042770Z","shell.execute_reply.started":"2024-08-27T08:47:27.946776Z","shell.execute_reply":"2024-08-27T08:47:28.041058Z"},"jupyter":{"source_hidden":true,"outputs_hidden":true},"collapsed":true,"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"Original data shape: (1797, 64)\nReduced data shape: (1797, 2)\n","output_type":"stream"}]},{"cell_type":"markdown","source":"**Reference**: https://www.geeksforgeeks.org/what-is-python-scikit-library/","metadata":{}}]}